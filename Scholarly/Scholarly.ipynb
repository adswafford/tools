{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2019-05-06 Scholarly-modified  \n",
    "Modification by Austin Swafford  \n",
    "This notebook is a modification of https://github.com/OrganicIrradiation/scholarly,  \n",
    "itself a fork of https://github.com/1ucian0/chalmers-web  \n",
    "    \n",
    "Several urls have been updated by Google so the code needed to be modified.  \n",
    "This seems to be captured in the pull requests on the OrganicIrradiation  \n",
    "but these have not yet been merged.  \n",
    "\n",
    "The environment needed to run this notebook is at gscholar.yaml in this same repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import arrow\n",
    "import bibtexparser\n",
    "import codecs\n",
    "import hashlib\n",
    "import pprint\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_GOOGLEID = hashlib.md5(str(random.random()).encode('utf-8')).hexdigest()[:16]\n",
    "_COOKIES = {'GSP': 'ID={0}:CF=4'.format(_GOOGLEID)}\n",
    "_HEADERS = {\n",
    "    'accept-language': 'en-US,en',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/41.0.2272.76 Chrome/41.0.2272.76 Safari/537.36',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml'\n",
    "    }\n",
    "_HOST = 'https://scholar.google.com'\n",
    "_AUTHSEARCH = '/citations?view_op=search_authors&hl=en&mauthors={0}'\n",
    "_CITATIONAUTH = '/citations?user={0}&hl=en'\n",
    "_CITATIONPUB = '/citations?view_op=view_citation&citation_for_view={0}'\n",
    "_KEYWORDSEARCH = '/citations?view_op=search_authors&hl=en&mauthors=label:{0}'\n",
    "_PUBSEARCH = '/scholar?q={0}'\n",
    "_SCHOLARPUB = '/scholar?oi=bibs&hl=en&cites={0}'\n",
    "\n",
    "_CITATIONAUTHRE = r'user=([\\w-]*)'\n",
    "_CITATIONPUBRE = r'citation_for_view=([\\w-]*:[\\w-]*)'\n",
    "_SCHOLARCITERE = r'gs_ocit\\(event,\\'([\\w-]*)\\''\n",
    "_SCHOLARPUBRE = r'cites=([\\w-]*)'\n",
    "_EMAILAUTHORRE = r'Verified email at '\n",
    "\n",
    "_SESSION = requests.Session()\n",
    "_PAGESIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Author(object):\n",
    "    \"\"\"Returns an object for a single author\"\"\"\n",
    "    def __init__(self, __data):\n",
    "        if isinstance(__data, str):\n",
    "            self.id = __data\n",
    "        else:\n",
    "            self.id = re.findall(_CITATIONAUTHRE, __data('a')[0]['href'])[0]\n",
    "            self.url_picture = _HOST+'/citations?view_op=medium_photo&user={}'.format(self.id)\n",
    "            self.name = __data.find('h3', class_='gs_ai_name').text\n",
    "            affiliation = __data.find('div', class_='gs_ai_aff')\n",
    "            if affiliation:\n",
    "                self.affiliation = affiliation.text\n",
    "            email = __data.find('div', class_='gs_ai_eml')\n",
    "            if email:\n",
    "                self.email = re.sub(_EMAILAUTHORRE, r'@', email.text)\n",
    "            self.interests = [i.text.strip() for i in\n",
    "                              __data.find_all('a', class_='gs_ai_one_int')]\n",
    "            citedby = __data.find('div', class_='gs_ai_cby')\n",
    "            if citedby and citedby.text != '':\n",
    "                self.citedby = int(citedby.text[9:])\n",
    "        self._filled = False\n",
    "\n",
    "    def fill(self):\n",
    "        \"\"\"Populate the Author with information from their profile\"\"\"\n",
    "        gs_prefix='gsc'\n",
    "        url_citations = _CITATIONAUTH.format(self.id)\n",
    "        url = '{0}&pagesize={1}'.format(url_citations, _PAGESIZE)\n",
    "        self.gs_website = _HOST+url\n",
    "        #print(_HOST+url)\n",
    "        soup = _get_soup(_HOST+url)\n",
    "        #print(soup)\n",
    "        self.name = soup.find('div', id=gs_prefix + '_prf_in').text\n",
    "        self.affiliation = soup.find('div', class_=gs_prefix + '_prf_il').text\n",
    "        self.interests = [i.text.strip() for i in soup.find_all('a', class_=gs_prefix + '_prf_inta')]\n",
    "        \n",
    "        # h-index, i10-index and h-index, i10-index in the last 5 years\n",
    "        index = soup.find_all('td', class_='gs_rsb_std')\n",
    "        if index:\n",
    "            self.citedby = int(index[0].text)\n",
    "            self.citedby5y = int(index[1].text)\n",
    "            self.hindex = int(index[2].text)\n",
    "            self.hindex5y = int(index[3].text)\n",
    "            self.i10index = int(index[4].text)\n",
    "            self.i10index5y = int(index[5].text)\n",
    "        else:\n",
    "            self.hindex = self.hindex5y = self.i10index = self.i10index5y = 0\n",
    "\n",
    "        # number of citations per year\n",
    "        years = [int(y.text) for y in soup.find_all('span', class_=gs_prefix + '_g_t')]\n",
    "        cites = [int(c.text) for c in soup.find_all('span', class_=gs_prefix + '_g_al')]\n",
    "        self.cites_per_year = dict(zip(years, cites))\n",
    "\n",
    "        # co-authors\n",
    "        self.coauthors = []\n",
    "        for row in soup.find_all('span', class_=gs_prefix + '_rsb_a_desc'):\n",
    "            new_coauthor = Author(re.findall(_CITATIONAUTHRE, row('a')[0]['href'])[0])\n",
    "            new_coauthor.name = row.find(tabindex=\"-1\").text\n",
    "            new_coauthor.affiliation = row.find(class_=gs_prefix + \"_rsb_a_ext\").text\n",
    "            self.coauthors.append(new_coauthor)\n",
    "\n",
    "\n",
    "        self.publications = list()\n",
    "        pubstart = 0\n",
    "        while True:\n",
    "            for row in soup.find_all('tr', class_=gs_prefix + '_a_tr'):\n",
    "                new_pub = Publication(row, 'citations')\n",
    "                self.publications.append(new_pub)\n",
    "            if 'disabled' not in soup.find('button', id=gs_prefix + '_bpf_more').attrs:\n",
    "                pubstart += _PAGESIZE\n",
    "                url = '{0}&cstart={1}&pagesize={2}'.format(url_citations, pubstart, _PAGESIZE)\n",
    "                soup = _get_soup(_HOST+url)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        self._filled = True\n",
    "        return self\n",
    "\n",
    "    def __str__(self):\n",
    "        return pprint.pformat(self.__dict__)\n",
    "\n",
    "class Publication(object):\n",
    "    \"\"\"Returns an object for a single publication\"\"\"\n",
    "    def __init__(self, __data, pubtype=None):\n",
    "        self.bib = dict()\n",
    "        self.source = pubtype\n",
    "        if self.source == 'citations':\n",
    "            self.bib['title'] = __data.find('a', class_='gsc_a_at').text\n",
    "            self.id_citations = re.findall(_CITATIONPUBRE, __data.find('a', class_='gsc_a_at')['data-href'])[0]\n",
    "            citedby = __data.find(class_='gsc_a_ac')\n",
    "            if citedby and not (citedby.text.isspace() or citedby.text == ''):\n",
    "                self.citedby = int(citedby.text)\n",
    "            year = __data.find(class_='gsc_a_h')\n",
    "            if year and year.text and not year.text.isspace() and len(year.text)>0:\n",
    "                self.bib['year'] = int(year.text)\n",
    "        elif self.source == 'scholar':\n",
    "            databox = __data.find('div', class_='gs_ri')\n",
    "            title = databox.find('h3', class_='gs_rt')\n",
    "            if title.find('span', class_='gs_ctu'): # A citation\n",
    "                title.span.extract()\n",
    "            elif title.find('span', class_='gs_ctc'): # A book or PDF\n",
    "                title.span.extract()\n",
    "            self.bib['title'] = title.text.strip()\n",
    "            if title.find('a'):\n",
    "                self.bib['url'] = title.find('a')['href']\n",
    "            authorinfo = databox.find('div', class_='gs_a')\n",
    "            self.bib['author'] = ' and '.join([i.strip() for i in authorinfo.text.split(' - ')[0].split(',')])\n",
    "            if databox.find('div', class_='gs_rs'):\n",
    "                self.bib['abstract'] = databox.find('div', class_='gs_rs').text\n",
    "                if self.bib['abstract'][0:8].lower() == 'abstract':\n",
    "                    self.bib['abstract'] = self.bib['abstract'][9:].strip()\n",
    "            lowerlinks = databox.find('div', class_='gs_fl').find_all('a')\n",
    "            for link in lowerlinks:\n",
    "                if 'Import into BibTeX' in link.text:\n",
    "                    self.url_scholarbib = link['href']\n",
    "                if 'Cited by' in link.text:\n",
    "                    self.citedby = int(re.findall(r'\\d+', link.text)[0])\n",
    "                    self.id_scholarcitedby = re.findall(_SCHOLARPUBRE, link['href'])[0]\n",
    "            if __data.find('div', class_='gs_ggs gs_fl'):\n",
    "                self.bib['eprint'] = __data.find('div', class_='gs_ggs gs_fl').a['href']\n",
    "        self._filled = False\n",
    "\n",
    "    def fill(self):\n",
    "        \"\"\"Populate the Publication with information from its profile\"\"\"\n",
    "        if self.source == 'citations':\n",
    "            url = _CITATIONPUB.format(self.id_citations)\n",
    "            soup = _get_soup(_HOST+url)\n",
    "            self.bib['title'] = soup.find('div', id='gsc_vcd_title').text\n",
    "            if soup.find('a', class_='gsc_vcd_title_link'):\n",
    "                self.bib['url'] = soup.find('a', class_='gsc_vcd_title_link')['href']\n",
    "            for item in soup.find_all('div', class_='gs_scl'):\n",
    "                key = item.find(class_='gsc_vcd_field').text\n",
    "                val = item.find(class_='gsc_vcd_value')\n",
    "                if key == 'Authors':\n",
    "                    self.bib['author'] = ' and '.join([i.strip() for i in val.text.split(',')])\n",
    "                elif key == 'Journal':\n",
    "                    self.bib['journal'] = val.text\n",
    "                elif key == 'Volume':\n",
    "                    self.bib['volume'] = val.text\n",
    "                elif key == 'Issue':\n",
    "                    self.bib['number'] = val.text\n",
    "                elif key == 'Pages':\n",
    "                    self.bib['pages'] = val.text\n",
    "                elif key == 'Publisher':\n",
    "                    self.bib['publisher'] = val.text\n",
    "                elif key == 'Publication date':\n",
    "                    self.bib['year'] = arrow.get(val.text).year\n",
    "                elif key == 'Description':\n",
    "                    if val.text[0:8].lower() == 'abstract':\n",
    "                        val = val.text[9:].strip()\n",
    "                    self.bib['abstract'] = val\n",
    "                elif key == 'Total citations':\n",
    "                    self.id_scholarcitedby = re.findall(_SCHOLARPUBRE, val.a['href'])[0]\n",
    "            if soup.find('div', class_='gsc_vcd_title_ggi'):\n",
    "                self.bib['eprint'] = soup.find('div', class_='gsc_vcd_title_ggi').a['href']\n",
    "            self._filled = True\n",
    "        elif self.source == 'scholar':\n",
    "            bibtex = _get_page(self.url_scholarbib)\n",
    "            self.bib.update(bibtexparser.loads(bibtex).entries[0])\n",
    "            self._filled = True\n",
    "        return self\n",
    "\n",
    "    def get_citedby(self):\n",
    "        \"\"\"Searches GScholar for other articles that cite this Publication and\n",
    "        returns a Publication generator.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'id_scholarcitedby'):\n",
    "            self.fill()\n",
    "        if hasattr(self, 'id_scholarcitedby'):\n",
    "            url = _SCHOLARPUB.format(requests.utils.quote(self.id_scholarcitedby))\n",
    "            soup = _get_soup(_HOST+url)\n",
    "            return _search_scholar_soup(soup)\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def __str__(self):\n",
    "        return pprint.pformat(self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_page(pagerequest):\n",
    "    \"\"\"Return the data for a page on scholar.google.com\"\"\"\n",
    "    # Note that we include a sleep to avoid overloading the scholar server\n",
    "    time.sleep(5+random.uniform(0, 5))\n",
    "    resp = _SESSION.get(pagerequest, headers=_HEADERS, cookies=_COOKIES)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.text\n",
    "    if resp.status_code == 503:\n",
    "        # Inelegant way of dealing with the G captcha\n",
    "        raise Exception('Error: {0} {1}'.format(resp.status_code, resp.reason))\n",
    "        # TODO: Need to fix captcha handling\n",
    "        # dest_url = requests.utils.quote(_SCHOLARHOST+pagerequest)\n",
    "        # soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        # captcha_url = soup.find('img').get('src')\n",
    "        # resp = _handle_captcha(captcha_url)\n",
    "        # return _get_page(re.findall(r'https:\\/\\/(?:.*?)(\\/.*)', resp)[0])\n",
    "    else:\n",
    "        raise Exception('Error: {0} {1}'.format(resp.status_code, resp.reason))\n",
    "        \n",
    "def _get_soup(pagerequest):\n",
    "    \"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\n",
    "    html = _get_page(pagerequest)\n",
    "    html = html.replace(u'\\xa0', u' ')\n",
    "    return BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "def search_author_alt(name):\n",
    "    \"\"\"Search by author name and return a generator of Author objects\"\"\"\n",
    "    url = _AUTHSEARCH.format(requests.utils.quote(name))\n",
    "    soup = _get_soup(_HOST+url)\n",
    "    return _search_citation_soup(soup)\n",
    "\n",
    "def _search_citation_soup(soup):\n",
    "    \"\"\"Generator that returns Author objects from the author search page\"\"\"\n",
    "    while True:\n",
    "        for row in soup.find_all('div', 'gsc_1usr'):\n",
    "            #print(row)\n",
    "            yield Author(row)\n",
    "        next_button = soup.find(class_='gs_btnPR gs_in_ib gs_btn_half gs_btn_lsb gs_btn_srt gsc_pgn_pnx')\n",
    "        if next_button and 'disabled' not in next_button.attrs:\n",
    "            url = next_button['onclick'][17:-1]\n",
    "            url = codecs.getdecoder(\"unicode_escape\")(url)[0]\n",
    "            soup = _get_soup(_HOST+url)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are new methods introduced to enable me to get a list of multiple authors at onces\n",
    "def multi_author_search(list_of_authors):\n",
    "    author_dict={}\n",
    "    gs_dict= {}\n",
    "    for name in list_of_authors:\n",
    "        name = name.strip(' ,')\n",
    "        print(name)\n",
    "        name_iter = search_author_alt(name)\n",
    "        for author in name_iter:\n",
    "            test = author.fill()\n",
    "            if 'ucsd' in test.email or 'sdsc' in test.email:\n",
    "                author_dict[name]= test\n",
    "            else:\n",
    "                print(\"Email: \" + test.email + \" does not contain 'ucsd'. Skipping\")\n",
    "    return author_dict\n",
    "\n",
    "def get_citations(author_dict,name='Total',year='Total'):\n",
    "    total_citations= 0\n",
    "    if name == year == 'Total':\n",
    "        for author in author_dict:\n",
    "            total_citations = total_citations + author_dict[author].citedby\n",
    "    elif name == 'Total':\n",
    "        for author in author_dict:\n",
    "            total_citations = total_citations + author_dict[author].cites_per_year[int(year)]\n",
    "    elif year == 'Total':\n",
    "        total_citations = author_dict[name].citedby\n",
    "    else:\n",
    "        total_citations = author_dict[name].cites_per_year[int(year)]\n",
    "    \n",
    "    return total_citations\n",
    "\n",
    "def get_author_list(filename,head=0,index=0,delim='\\t'):\n",
    "    author_list =list(pd.read_csv(filename,header=head,index_col=index,sep=delim).index)\n",
    "    author_list = [auth for auth in author_list if str(auth) != 'nan']\n",
    "    return author_list\n",
    "\n",
    "def get_publication_table(author_dict):\n",
    "    publication_df = pd.DataFrame(columns = ['Publications','Total Citations','Interests','Email','GoogleScholar_URL'])\n",
    "    for a in author_dict.keys():\n",
    "        publication_df.at[a,'Publications'] = len(author_dict[a].publications)\n",
    "        publication_df.at[a,'Total Citations'] = author_dict[a].citedby\n",
    "        publication_df.at[a,'Interests'] = str(author_dict[a].interests).replace('[','').replace(']','').replace(\"'\",\"\")\n",
    "        publication_df.at[a,'Email'] = author_dict[a].email\n",
    "        publication_df.at[a,'GoogleScholar_URL'] = author_dict[a].gs_website\n",
    "        year = 1970\n",
    "        while year < 2022:\n",
    "            try: \n",
    "                cites_year = author_dict[a].cites_per_year[int(year)]\n",
    "            except:\n",
    "                cites_year = np.nan\n",
    "            publication_df.at[a,str(year)]= cites_year\n",
    "            year += 1\n",
    "    return publication_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eric Allen',\n",
       " 'Ilkay Altintas',\n",
       " 'Lihini Aluwihare',\n",
       " 'Rommie Amaro',\n",
       " 'Cheryl Anderson',\n",
       " 'Maria Rosario Araneta',\n",
       " 'Scott Baden',\n",
       " 'Vineet Bafna',\n",
       " 'Nuno Bandeira',\n",
       " 'Kim Barrett',\n",
       " 'Andy Bartko',\n",
       " 'Douglas Bartlett',\n",
       " 'Shrikant Bhute',\n",
       " 'Ethan Bier',\n",
       " 'Cinnamon Bloss',\n",
       " 'Lars Bode',\n",
       " 'Brigid Boland',\n",
       " 'Jeff Bowman',\n",
       " 'John Bradley',\n",
       " 'Sheldon Brown',\n",
       " 'Sara Browne',\n",
       " 'Linda Brubaker',\n",
       " 'Jane Burns',\n",
       " 'Kalen Cantrell',\n",
       " 'Carolina Carpenter',\n",
       " 'John Chang',\n",
       " 'Lakshmi Chilukuri',\n",
       " 'Hiu Chu',\n",
       " 'Douglas Conrad',\n",
       " 'Shane Crotty',\n",
       " 'Laura Crotty Alexander',\n",
       " 'Sheila Crowe',\n",
       " 'Matt Daugherty',\n",
       " 'Adam DeConde',\n",
       " 'Anna Di Nardo',\n",
       " 'Pieter Dorrestein',\n",
       " 'Donald Durden',\n",
       " 'Rachel Dutton',\n",
       " 'Peter Ernst',\n",
       " 'Lisa Eyler',\n",
       " 'William Fenical',\n",
       " 'Gary Firestein',\n",
       " 'Stephanie Fraley',\n",
       " 'Wenxian Fu',\n",
       " 'Pascal Gagneux',\n",
       " 'Richard Gallo',\n",
       " 'Olivier George',\n",
       " 'Lena Gerwick',\n",
       " 'Partho Ghosh',\n",
       " 'Jack Gilbert',\n",
       " 'Chris Glass',\n",
       " 'James Golden',\n",
       " 'Susan Golden',\n",
       " 'David Gonzalez',\n",
       " 'Diana Guttierez',\n",
       " 'Gabriel Haddad',\n",
       " 'Shalisa Hansen',\n",
       " 'Nan Hao',\n",
       " 'Jeff Hasty',\n",
       " 'Robert Heaton',\n",
       " 'Suzi Hong',\n",
       " 'Shi Huang',\n",
       " 'Alisa Huffaker',\n",
       " 'Terry Hwa',\n",
       " 'Trey Ideker',\n",
       " 'Jules Jaffe',\n",
       " 'Mohit Jain',\n",
       " 'Paul Jensen',\n",
       " 'Dilip Jeste',\n",
       " 'Deborah Kado',\n",
       " 'Iveta Kalcheva',\n",
       " 'Michael Karin',\n",
       " 'Soni Khandelwal',\n",
       " 'Ken Kreutz-Delgado',\n",
       " 'Sergey Kryazhimskiy',\n",
       " 'Vipin Kumar',\n",
       " 'Michael Kurisu',\n",
       " 'Carolyn Kurle',\n",
       " 'Louise Laurent',\n",
       " 'Shelley Lawrence',\n",
       " 'Scott Lippman',\n",
       " 'Rohit Loomba',\n",
       " 'Li-Fan Lu',\n",
       " 'Emily Lukacz',\n",
       " 'Cressida Madigan',\n",
       " 'Robert Mak',\n",
       " 'Prashant Mali',\n",
       " 'Michael Matthias',\n",
       " 'Stephen Mayfield',\n",
       " 'Michael McCarthy',\n",
       " 'James McKerrow',\n",
       " 'Jill Mesirov',\n",
       " 'Christian Metallo',\n",
       " 'Justin Meyer',\n",
       " 'Siavash Mirarab',\n",
       " 'Bradley Moore',\n",
       " 'Jim Moore',\n",
       " 'Hayat Mousa',\n",
       " 'Tanya Nguyen',\n",
       " 'Sanjay Nigam',\n",
       " 'Victor Nizet',\n",
       " \"Anthony O'Donoghue\",\n",
       " 'Marygorret Obonyo',\n",
       " 'Jerrold Olefsky',\n",
       " 'Brian Palenik',\n",
       " 'Abraham Palmer',\n",
       " 'Bernhard Palsson',\n",
       " 'Sandip Patel',\n",
       " 'Kevin Patrick',\n",
       " 'Martin Paulus',\n",
       " 'Pavel Pevzner',\n",
       " 'Wayne Pfeiffer',\n",
       " 'Sheila Podell',\n",
       " 'Kit Pogliano',\n",
       " 'Kimberly Prather',\n",
       " 'David Pride',\n",
       " 'Lawrence Prince',\n",
       " 'Manuela Raffatellu',\n",
       " 'Brinda Rana',\n",
       " 'Lada Rasochova',\n",
       " 'Aspen Reese',\n",
       " 'Diana Rennison',\n",
       " 'Kyung Rhee',\n",
       " 'Jesus Rivera-Nieves',\n",
       " 'David Rosenberg',\n",
       " 'Tajana Rosing',\n",
       " 'Oliver Ryder',\n",
       " 'Julie Ryu',\n",
       " 'Bill Sandborn',\n",
       " 'Gordon Saxe',\n",
       " 'Eric Schmelz',\n",
       " 'Bernd Schnabl',\n",
       " 'Dorothy Sears',\n",
       " 'Jonathan Shurin',\n",
       " 'Larry Smarr',\n",
       " 'Jennifer Smith',\n",
       " 'Davey Smith',\n",
       " 'Se Jin Song',\n",
       " 'Shankar Subramaniam',\n",
       " 'Gurol Suel',\n",
       " 'Austin Swafford',\n",
       " 'Pam Taub',\n",
       " 'Glenn Tesler',\n",
       " 'Varykina Thackray',\n",
       " 'Emily Troemel',\n",
       " 'Ming Tsuang',\n",
       " 'Ajit Varki',\n",
       " 'Yoshiki Vazquez-Baeza',\n",
       " 'Joseph Wang',\n",
       " 'Nick Webster',\n",
       " 'Nadir Weibel',\n",
       " 'Kelly Weldon',\n",
       " 'Amir Zarrinpar',\n",
       " 'Karsten Zengler',\n",
       " 'Kun Zhang',\n",
       " 'Sheng Zhong',\n",
       " ' ',\n",
       " ' ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors= get_author_list('./20210104_Faculty_Members_and_CMI.csv',delim=\",\")\n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eric Allen\n"
     ]
    }
   ],
   "source": [
    "results = multi_author_search(authors)\n",
    "pub_table = get_publication_table(results)\n",
    "pub_table.to_csv('20200105_Google_Scholar_Results.tsv',sep='\\t',index=True,index_label ='Author')\n",
    "print(pub_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Citations: ' + str(pub_table['Total Citations'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
